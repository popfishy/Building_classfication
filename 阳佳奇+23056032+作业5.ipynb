{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 场景识别\n",
    "说明：由于本代码运行涉及到具体数据集，而数据集量偏大。下面仅仅在jupyter notebook中给出相应代码，具体运行结果截图表示。\n",
    "\n",
    "\n",
    "给定一批图片，利用深度学习算法，判断该图片究竟是属于哪座建筑的一部分。测试集图片未知，测试集图片，需要说明几点：\n",
    "* 测试图片均为前视视角图像；\n",
    "* 测试图片中既可能包含指定的建筑物的某个部分，也可能包含非指定建筑的某个部分，还有可能不包含任何需要识别的建筑物。\n",
    "* 要求最终的分类器按照下表输出相应的值。\n",
    "\n",
    "<img src=\"pic/分类类别.png\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.要求\n",
    "1. 对20类不同建筑样本进行分类，数据集需自行采集。\n",
    "2. 测试集不包含夜晚的照片。\n",
    "3. 采集时，设备以普通手机为主，采集后的图片会被裁剪、缩放。使用手机设备进行采集时，以前视视角进行拍摄，不会采用无人机拍摄建筑物的俯视图片。前视视角是指人在道路上正常行进的时候，从他的视角看到的建筑物的样子。但是前视视角不代表相机一定水平朝前正对着建筑物。测试集中还有建筑物的侧面照片。拍摄点一般都会在主路附近，不会刻意跑到建筑物的犄角旮旯去拍摄建筑物。\n",
    "4. 测试集包括一定比例负样本，负样本包含建筑类和非建筑类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.需求分析\n",
    "1. 对数据样本进行采集，其中采集的数据集文件夹目录层次如下：\n",
    "  \n",
    "<img src=\"pic/数据集.png\" style=\"zoom:50%;\" />\n",
    "\n",
    "2. 数据采集完成后，需对数据进行处理：\n",
    "- 数据清理：清理不符合要求的数据。比如树木等遮挡物超过80%的图片、拍摄过程中误拍的图片。\n",
    "- 数据预处理：统一数据格式，并为了防止数据量过大，将原始图片压缩到100W像素。\n",
    "- 数据增强：随机RGB(正负10)、随机亮度和对比度、随机仿射变换、随机裁剪。为了平衡不同类别之间的样本数量，每种类别统一增强到500张左右。\n",
    "  处理结果下图：\n",
    "<img src=\"pic/数据增强结果.png\" style=\"zoom:50%;\" />\n",
    "\n",
    "3. 20类样本+负样本共21类。负样本可以自行采集+网络上搜集建筑数据集+网络上相关建筑照片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 数据集根目录\n",
    "dataset_root = \"/home/yjq/dataset_augmentation\"\n",
    "target_total_pixels = 1000000\n",
    "max_num = 500\n",
    "labels = [\n",
    "    \"00_负样本\",\n",
    "    \"01_天河大楼\",\n",
    "    \"02_体育馆\",\n",
    "    \"03_航院主楼\",\n",
    "    \"04_01教学楼\",\n",
    "    \"05_02教学楼\",\n",
    "    \"06_03教学楼\",\n",
    "    \"07_图书馆\",\n",
    "    \"08_东跨线桥\",\n",
    "    \"09_西跨线桥\",\n",
    "    \"10_游泳馆\",\n",
    "    \"11_博士生楼\",\n",
    "    \"12_俱乐部\",\n",
    "    \"13_银河大楼\",\n",
    "    \"14_老图书馆\",\n",
    "    \"15_三院1号楼（主楼）\",\n",
    "    \"16_三院2号楼（老楼）\",\n",
    "    \"17_海天楼\",\n",
    "    \"18_四院主楼\",\n",
    "    \"19_北斗\",\n",
    "    \"20_校主楼\",\n",
    "]\n",
    "\n",
    "# 数据增强\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.RGBShift(r_shift_limit=5, g_shift_limit=5, b_shift_limit=5, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.2, p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=30, p=1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 遍历数据集，将每一张图片缩放到100W像素，保存压缩后的图像和3张数据增强后的图像\n",
    "for category_folder in os.listdir(dataset_root):\n",
    "    category_folder_path = os.path.join(dataset_root, category_folder)\n",
    "    output_folder_path = os.path.join(dataset_root, category_folder)\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "    if os.path.isdir(category_folder_path):\n",
    "        print(f\"Processing category: {category_folder}\")\n",
    "        num_cnt = len(os.listdir(category_folder_path))\n",
    "    for filename in os.listdir(category_folder_path):\n",
    "        file_path = os.path.join(category_folder_path, filename)\n",
    "        output_filename = os.path.join(output_folder_path, filename)\n",
    "        filename = filename.split(\".\")[0]\n",
    "    if os.path.isfile(file_path):\n",
    "            image = Image.open(file_path)\n",
    "            width = image.width\n",
    "            height = image.height\n",
    "            if (width * height) < target_total_pixels:\n",
    "                continue\n",
    "            else:\n",
    "                scale_factor = (target_total_pixels / (width * height)) ** 0.5\n",
    "                target_width = int(width * scale_factor)\n",
    "                target_height = int(height * scale_factor)\n",
    "                image = image.resize(\n",
    "                    (target_width, target_height), resample=Image.BILINEAR\n",
    "                )\n",
    "            image.save(output_folder_path + \"/\" + filename + \".jpg\")\n",
    "            image = np.array(image)\n",
    "            for i in range(3):\n",
    "                output_filename = (\n",
    "                    output_folder_path + \"/\" + filename + \"_\" + str(i) + \".jpg\"\n",
    "                )\n",
    "                output_filename = os.path.join(\n",
    "                    output_folder_path, filename + \"_\" + str(i) + \".jpg\"\n",
    "                )\n",
    "                transformed = transform(image=image)[\"image\"]\n",
    "                transformed = cv2.cvtColor(transformed, cv2.COLOR_RGB2BGR)\n",
    "                cv2.imencode(\".jpg\", transformed)[1].tofile(output_filename)\n",
    "                num_cnt = num_cnt + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.训练环境\n",
    "* 电脑型号：13th Gen Intel® Core™ i7-13700KF × 24 + RTX 4070Ti显卡\n",
    "* Ubuntu20.04环境 + CUDA12.2\n",
    "* Vscode开发环境\n",
    "\n",
    "<img src=\"pic/环境.png\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 使用Resnet50模型微调\n",
    "2. 训练结果Resnet50模型在测试集上的正确率在89%左右\n",
    "   \n",
    "<img src=\"pic/restnet.png\" style=\"zoom:50%;\" />\n",
    "\n",
    "3. Loss曲线\n",
    "\n",
    "<img src=\"pic/Loss.png\" style=\"zoom:15%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入数据\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "import torch.utils.data as tud\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model.inception_resnet_v2 import Inception_ResNetv2\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "dataset_root = \"/home/yjq/dataset_augmentation\"\n",
    "global_model_name = \"resnet50\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "writer = SummaryWriter(\"logs\")\n",
    "\n",
    "batch_size = 32\n",
    "input_size = 256\n",
    "num_class = 21\n",
    "\n",
    "f = open(\"result_\" + global_model_name + \".txt\", \"w\")\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(\n",
    "    root=dataset_root,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Resize(280),  # 调整图像短边\n",
    "            torchvision.transforms.CenterCrop(input_size),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(dataset, \"\\n\")\n",
    "print(\"classes:\\n\", dataset.classes, \"\\n\")\n",
    "\n",
    "# Split dataset into train and test (7:3)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [int(len(dataset) * 0.7), len(dataset) - int(len(dataset) * 0.7)]\n",
    ")\n",
    "train_dataloader = tud.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = tud.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def initialize_model(model_name, num_class, use_pretrained, feature_extract):\n",
    "    if model_name == \"resnet50\":\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        if feature_extract:  # do not update the parameters\n",
    "            for param in model_ft.parameters():\n",
    "                param.requires_grad = False\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_class)\n",
    "    else:\n",
    "        print(\"model not implemented\")\n",
    "        return None\n",
    "    return model_ft\n",
    "\n",
    "def train_model(model, train_dataloader, loss_fn, optimizer, epoch):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_corrects = 0.0\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        total_corrects += torch.sum(preds.eq(labels))\n",
    "    epoch_loss = total_loss / len(train_dataloader.dataset)\n",
    "    epoch_accuracy = total_corrects / len(train_dataloader.dataset)\n",
    "    f.write(\n",
    "        \"Epoch:{}, Training Loss:{}, Traning Acc:{}\\n\".format(\n",
    "            epoch, epoch_loss, epoch_accuracy\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Epoch:{}, Training Loss:{}, Traning Acc:{}\\n\".format(\n",
    "            epoch, epoch_loss, epoch_accuracy\n",
    "        )\n",
    "    )\n",
    "    writer.add_scalar(\"Loss/train\", epoch, epoch_loss)\n",
    "    writer.add_scalar(\"Accuracy/train\", epoch, epoch_accuracy)\n",
    "\n",
    "\n",
    "def test_model(model, test_dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_corrects = 0.0\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(test_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_corrects += torch.sum(preds.eq(labels))\n",
    "    epoch_loss = total_loss / len(test_dataloader.dataset)\n",
    "    epoch_accuracy = total_corrects / len(test_dataloader.dataset)\n",
    "    f.write(\"Test Loss:{}, Test Acc:{}\\n\".format(epoch_loss, epoch_accuracy))\n",
    "    print(\"Test Loss:{}, Test Acc:{}\\n\".format(epoch_loss, epoch_accuracy))\n",
    "    writer.add_scalar(\"Loss/test\", epoch, epoch_loss)\n",
    "    writer.add_scalar(\"Accuracy/test\", epoch, epoch_accuracy)\n",
    "    return epoch_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集输出结果为：\n",
    "\n",
    "<img src=\"pic/datasets.png\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行训练\n",
    "model = initialize_model(global_model_name, 21, use_pretrained=True, feature_extract=True)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "num_epochs = 80\n",
    "best_epoch = 0\n",
    "best_acc = 0.95\n",
    "test_accuracy_hist = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model, train_dataloader, loss_fn, optimizer, epoch)\n",
    "    acc = test_model(model, test_dataloader, loss_fn)\n",
    "    test_accuracy_hist.append(acc.item())\n",
    "    for name, param in model.named_parameters():\n",
    "        writer.add_histogram(name, param, epoch)\n",
    "        writer.add_histogram(f\"{name}.grad\", param.grad, epoch)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), \"Resnet50_best.pth\")\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(\n",
    "            model.state_dict(), global_model_name + \"_\" + str(epoch + 1) + \".pth\"\n",
    "        )\n",
    "f.close()\n",
    "writer.close()\n",
    "torch.save(model.state_dict(), global_model_name + \"_\" + str(epoch + 1) + \".pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 使用Inception_Resnet_v2网络进行训练\n",
    "2. 训练结果显示Inception_Resnet_v2在测试集上的正确率能达到97%，能满足任务需要\n",
    "\n",
    "<img src=\"pic/inception_resnet2.png\" style=\"zoom:50%;\" />\n",
    "\n",
    "3. 训练过程中使用nvitop查看GPU占用率，使用System Monitor查看CPU占用情况\n",
    "\n",
    "<img src=\"pic/nvitop.png\" style=\"zoom:50%;\" />\n",
    "\n",
    "<img src=\"pic/cpu.png\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#搭建Inception_Resnet_v2网络\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding, stride=1, bias=True):\n",
    "        super(Conv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Reduction_A(nn.Module):\n",
    "    # 35 -> 17\n",
    "    def __init__(self, in_channels, k, l, m, n):\n",
    "        super(Reduction_A, self).__init__()\n",
    "        self.branch_0 = Conv2d(in_channels, n, 3, stride=2, padding=0, bias=False)\n",
    "        self.branch_1 = nn.Sequential(\n",
    "            Conv2d(in_channels, k, 1, stride=1, padding=0, bias=False),\n",
    "            Conv2d(k, l, 3, stride=1, padding=1, bias=False),\n",
    "            Conv2d(l, m, 3, stride=2, padding=0, bias=False),\n",
    "        )\n",
    "        self.branch_2 = nn.MaxPool2d(3, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch_0(x)\n",
    "        x1 = self.branch_1(x)\n",
    "        x2 = self.branch_2(x)\n",
    "        return torch.cat((x0, x1, x2), dim=1) # 17 x 17 x 1024\n",
    "\n",
    "class Stem(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Stem, self).__init__()\n",
    "        self.conv2d_1a_3x3 = Conv2d(in_channels, 32, 3, stride=2, padding=0, bias=False)\n",
    "\n",
    "        self.conv2d_2a_3x3 = Conv2d(32, 32, 3, stride=1, padding=0, bias=False)\n",
    "        self.conv2d_2b_3x3 = Conv2d(32, 64, 3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.mixed_3a_branch_0 = nn.MaxPool2d(3, stride=2, padding=0)\n",
    "        self.mixed_3a_branch_1 = Conv2d(64, 96, 3, stride=2, padding=0, bias=False)\n",
    "\n",
    "        self.mixed_4a_branch_0 = nn.Sequential(\n",
    "            Conv2d(160, 64, 1, stride=1, padding=0, bias=False),\n",
    "            Conv2d(64, 96, 3, stride=1, padding=0, bias=False),\n",
    "        )\n",
    "        self.mixed_4a_branch_1 = nn.Sequential(\n",
    "            Conv2d(160, 64, 1, stride=1, padding=0, bias=False),\n",
    "            Conv2d(64, 64, (1, 7), stride=1, padding=(0, 3), bias=False),\n",
    "            Conv2d(64, 64, (7, 1), stride=1, padding=(3, 0), bias=False),\n",
    "            Conv2d(64, 96, 3, stride=1, padding=0, bias=False)\n",
    "        )\n",
    "\n",
    "        self.mixed_5a_branch_0 = Conv2d(192, 192, 3, stride=2, padding=0, bias=False)\n",
    "        self.mixed_5a_branch_1 = nn.MaxPool2d(3, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1a_3x3(x) # 149 x 149 x 32\n",
    "        x = self.conv2d_2a_3x3(x) # 147 x 147 x 32\n",
    "        x = self.conv2d_2b_3x3(x) # 147 x 147 x 64\n",
    "        x0 = self.mixed_3a_branch_0(x)\n",
    "        x1 = self.mixed_3a_branch_1(x)\n",
    "        x = torch.cat((x0, x1), dim=1) # 73 x 73 x 160\n",
    "        x0 = self.mixed_4a_branch_0(x)\n",
    "        x1 = self.mixed_4a_branch_1(x)\n",
    "        x = torch.cat((x0, x1), dim=1) # 71 x 71 x 192\n",
    "        x0 = self.mixed_5a_branch_0(x)\n",
    "        x1 = self.mixed_5a_branch_1(x)\n",
    "        x = torch.cat((x0, x1), dim=1) # 35 x 35 x 384\n",
    "        return x\n",
    "\n",
    "\n",
    "class Inception_A(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Inception_A, self).__init__()\n",
    "        self.branch_0 = Conv2d(in_channels, 96, 1, stride=1, padding=0, bias=False)\n",
    "        self.branch_1 = nn.Sequential(\n",
    "            Conv2d(in_channels, 64, 1, stride=1, padding=0, bias=False),\n",
    "            Conv2d(64, 96, 3, stride=1, padding=1, bias=False),\n",
    "        )\n",
    "        self.branch_2 = nn.Sequential(\n",
    "            Conv2d(in_channels, 64, 1, stride=1, padding=0, bias=False),\n",
    "            Conv2d(64, 96, 3, stride=1, padding=1, bias=False),\n",
    "            Conv2d(96, 96, 3, stride=1, padding=1, bias=False),\n",
    "        )\n",
    "        self.brance_3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, 1, padding=1, count_include_pad=False),\n",
    "            Conv2d(384, 96, 1, stride=1, padding=0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch_0(x)\n",
    "        x1 = self.branch_1(x)\n",
    "        x2 = self.branch_2(x)\n",
    "        x3 = self.brance_3(x)\n",
    "        return torch.cat((x0, x1, x2, x3), dim=1)\n",
    "\n",
    "\n",
    "class Inception_B(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Inception_B, self).__init__()\n",
    "        self.branch_0 = Conv2d(in_channels, 384, 1, stride=1, padding=0, bias=False)\n",
    "        self.branch_1 = nn.Sequential(\n",
    "            Conv2d(in_channels, 192, 1, stride=1, padding=0, bias=False),\n",
    "            Conv2d(192, 224, (1, 7), stride=1, padding=(0, 3), bias=False),\n",
    "            Conv2d(224, 256, (7, 1), stride=1, padding=(3, 0), bias=False),\n",
    "        )\n",
    "        self.branch_2 = nn.Sequential(\n",
    "            Conv2d(in_channels, 192, 1, stride=1, padding=0, bias=False),\n",
    "            Conv2d(192, 192, (7, 1), stride=1, padding=(3, 0), bias=False),\n",
    "            Conv2d(192, 224, (1, 7), stride=1, padding=(0, 3), bias=False),\n",
    "            Conv2d(224, 224, (7, 1), stride=1, padding=(3, 0), bias=False),\n",
    "            Conv2d(224, 256, (1, 7), stride=1, padding=(0, 3), bias=False)\n",
    "        )\n",
    "        self.branch_3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            Conv2d(in_channels, 128, 1, stride=1, padding=0, bias=False)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch_0(x)\n",
    "        x1 = self.branch_1(x)\n",
    "        x2 = self.branch_2(x)\n",
    "        x3 = self.branch_3(x)\n",
    "        return torch.cat((x0, x1, x2, x3), dim=1)\n",
    "\n",
    "\n",
    "class Reduction_B(nn.Module):\n",
    "    # 17 -> 8\n",
    "    def __init__(self, in_channels):\n",
    "        super(Reduction_B, self).__init__()\n",
    "        self.branch_0 = nn.Sequential(\n",
    "            Conv2d(in_channels, 192, 1, stride=1, padding=0, bias=False),\n",
    "            Conv2d(192, 192, 3, stride=2, padding=0, bias=False),\n",
    "        )\n",
    "        self.branch_1 = nn.Sequential(\n",
    "            Conv2d(in_channels, 256, 1, stride=1, padding=0, bias=False),\n",
    "            Conv2d(256, 256, (1, 7), stride=1, padding=(0, 3), bias=False),\n",
    "            Conv2d(256, 320, (7, 1), stride=1, padding=(3, 0), bias=False),\n",
    "            Conv2d(320, 320, 3, stride=2, padding=0, bias=False)\n",
    "        )\n",
    "        self.branch_2 = nn.MaxPool2d(3, stride=2, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch_0(x)\n",
    "        x1 = self.branch_1(x)\n",
    "        x2 = self.branch_2(x)\n",
    "        return torch.cat((x0, x1, x2), dim=1)  # 8 x 8 x 1536\n",
    "\n",
    "\n",
    "class Inception_C(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Inception_C, self).__init__()\n",
    "        self.branch_0 = Conv2d(in_channels, 256, 1, stride=1, padding=0, bias=False)\n",
    "\n",
    "        self.branch_1 = Conv2d(in_channels, 384, 1, stride=1, padding=0, bias=False)\n",
    "        self.branch_1_1 = Conv2d(384, 256, (1, 3), stride=1, padding=(0, 1), bias=False)\n",
    "        self.branch_1_2 = Conv2d(384, 256, (3, 1), stride=1, padding=(1, 0), bias=False)\n",
    "\n",
    "        self.branch_2 = nn.Sequential(\n",
    "            Conv2d(in_channels, 384, 1, stride=1, padding=0, bias=False),\n",
    "            Conv2d(384, 448, (3, 1), stride=1, padding=(1, 0), bias=False),\n",
    "            Conv2d(448, 512, (1, 3), stride=1, padding=(0, 1), bias=False),\n",
    "        )\n",
    "        self.branch_2_1 = Conv2d(512, 256, (1, 3), stride=1, padding=(0, 1), bias=False)\n",
    "        self.branch_2_2 = Conv2d(512, 256, (3, 1), stride=1, padding=(1, 0), bias=False)\n",
    "\n",
    "        self.branch_3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            Conv2d(in_channels, 256, 1, stride=1, padding=0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch_0(x)\n",
    "        x1 = self.branch_1(x)\n",
    "        x1_1 = self.branch_1_1(x1)\n",
    "        x1_2 = self.branch_1_2(x1)\n",
    "        x1 = torch.cat((x1_1, x1_2), 1)\n",
    "        x2 = self.branch_2(x)\n",
    "        x2_1 = self.branch_2_1(x2)\n",
    "        x2_2 = self.branch_2_2(x2)\n",
    "        x2 = torch.cat((x2_1, x2_2), dim=1)\n",
    "        x3 = self.branch_3(x)\n",
    "        return torch.cat((x0, x1, x2, x3), dim=1) # 8 x 8 x 1536\n",
    "\n",
    "\n",
    "class Inceptionv4(nn.Module):\n",
    "    def __init__(self, in_channels=3, classes=1000, k=192, l=224, m=256, n=384):\n",
    "        super(Inceptionv4, self).__init__()\n",
    "        blocks = []\n",
    "        blocks.append(Stem(in_channels))\n",
    "        for i in range(4):\n",
    "            blocks.append(Inception_A(384))\n",
    "        blocks.append(Reduction_A(384, k, l, m, n))\n",
    "        for i in range(7):\n",
    "            blocks.append(Inception_B(1024))\n",
    "        blocks.append(Reduction_B(1024))\n",
    "        for i in range(3):\n",
    "            blocks.append(Inception_C(1536))\n",
    "        self.features = nn.Sequential(*blocks)\n",
    "        self.global_average_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(1536, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_average_pooling(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入数据进行训练\n",
    "global_model_name = \"Inception_ResNetv2\"\n",
    "input_size = 299\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(\n",
    "    root=dataset_root,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Resize(300),  # 调整图像短边\n",
    "            torchvision.transforms.CenterCrop(input_size),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [int(len(dataset) * 0.7), len(dataset) - int(len(dataset) * 0.7)]\n",
    ")\n",
    "train_dataloader = tud.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = tud.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = Inception_ResNetv2()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "num_epochs = 80\n",
    "best_epoch = 0\n",
    "best_acc = 0.95\n",
    "test_accuracy_hist = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_model(model, train_dataloader, loss_fn, optimizer, epoch)\n",
    "    acc = test_model(model, test_dataloader, loss_fn)\n",
    "    test_accuracy_hist.append(acc.item())\n",
    "    for name, param in model.named_parameters():\n",
    "        writer.add_histogram(name, param, epoch)\n",
    "        writer.add_histogram(f\"{name}.grad\", param.grad, epoch)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), \"Inception_Resnet_v2_best.pth\")\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(\n",
    "            model.state_dict(), global_model_name + \"_\" + str(epoch + 1) + \".pth\"\n",
    "        )\n",
    "f.close()\n",
    "writer.close()\n",
    "\n",
    "torch.save(model.state_dict(), global_model_name + \"_\" + str(epoch + 1) + \".pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.测试\n",
    "使用任务提供的未知的验证集，根据验证结果统计分类正确率。分析Inception_Resnet_V2网络最终效果如何。\n",
    "\n",
    "<img src=\"pic/测试结果.png\" style=\"zoom:50%;\" />\n",
    "\n",
    "发现验证正确率为76.81%，分析原因可能有以下几点：\n",
    "* 负样本很难考虑到三号院相似建筑物。\n",
    "* 部分测试样本对比度和曝光较高，数据增强时阈值设置较低。\n",
    "* 部分类别间相似度高，在仅提供有限视角的情况下，存在一定概率分类错误。\n",
    "\n",
    "\n",
    "改进：\n",
    "* 在网络上搜索国防科技大学相关图片，对图片进行爬取并人工去除场景识别中相关正样本，对剩下的负样本进行图像增强，加入到数据集负样本之中。\n",
    "* 图像增强时，随机曝光度阈值提高。\n",
    "\n",
    "<img src=\"pic/负样本.png\" style=\"zoom:30%;\" />\n",
    "\n",
    "重新进行训练，并对网络进行微调，最终在训练集上正确率为98.4%正确率，测试集96.7%正确率。使用任务提供的未知的验证集，根据验证结果统计分类正确率。本次验证正确率提升到了85.5%。\n",
    "\n",
    "<img src=\"pic/测试结果2.png\" style=\"zoom:50%;\" />\n",
    "\n",
    "发现之前存在的负样本分类错误基本上去除，大部分错误主要是验证集部分图片年代稍显久远，曝光和色彩较差。下图尽管预测正确，但是预测概率值也仅仅为0.28，表示模型也极不确定其具体类别。\n",
    "\n",
    "<img src=\"pic/概率值低.png\" style=\"zoom:30%;\" />\n",
    "\n",
    "类似图片预测概率值都比较低，低于0.7,而正确分类样本的预测概率值都接近0.99.在具体分类时，可以将预测概率值较低的图片交给人类辅助处理。例如以下该种图片样本为预测值为西跨线桥，但是真实值却为东跨线桥。\n",
    "\n",
    "<img src=\"pic/验证集样本.png\" style=\"zoom:30%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"Inception_ResNetv2_40.pth\"\n",
    "datas_path = \"test_data\"\n",
    "\n",
    "# 加载模型\n",
    "model = Inception_ResNetv2()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "test_pic = []\n",
    "for filename in os.listdir(datas_path):\n",
    "    test_pic.append(filename)\n",
    "test_pic = sorted(test_pic)\n",
    "for filename in test_pic:\n",
    "    file_path = os.path.join(datas_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        image = Image.open(file_path)\n",
    "        # 加载图像并进行预处理\n",
    "        if (image.width * image.height) > target_total_pixels:\n",
    "            scale_factor = (target_total_pixels / (image.width * image.height)) ** 0.5\n",
    "            target_width = int(image.width * scale_factor)\n",
    "            target_height = int(image.height * scale_factor)\n",
    "            image = image.resize((target_width, target_height), resample=Image.BILINEAR)\n",
    "        image_tensor = transform(image)\n",
    "        image_tensor = image_tensor.unsqueeze(0)  # 添加批次维度\n",
    "        # 进行预测\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image_tensor)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            predicted_value, predicted = torch.max(outputs, 1)\n",
    "            if predicted_value.item() < 0.4:\n",
    "                predicted = 0\n",
    "        # 打印预测结果\n",
    "        print(\n",
    "            \"图片名称:{}, 预测结果:{}, 预测概率值:{:.4f}, 预测标签为:{}\".format(\n",
    "                filename,\n",
    "                predicted.item(),\n",
    "                predicted_value.item(),\n",
    "                labels[predicted.item()],\n",
    "            )\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
